{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment: Анализ изображений\n",
    "\n",
    "Задача заключается в том, чтобы применить предобученную на imagenet нейронную сеть на практической задаче классификации автомобилей. \n",
    "\n",
    "Учиться применять нейронные сети для анализа изображений мы будем на библиотеке TensorFlow. Это известный опенсорсный проект, разработанный инженерами Google Brain Team. Подробнее почитать о TensorFlow можно на официальном сайте, на [гитхабе](https://github.com/tensorflow/tensorflow) или [на хабре](https://habrahabr.ru/post/270543/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Данные\n",
    "\n",
    "Скачать данные нужно тут: https://yadi.sk/d/6m_KbM4HvmLfs \n",
    "\n",
    "Данные это часть выборки _Cars Dataset_ ([link](http://ai.stanford.edu/~jkrause/cars/car_dataset.html)). Исходный датасет содержит 16,185 изображений автомобилей, принадлежащих к 196 классам. Данные разделены на 8,144 тренировочных и 8,041 тестовых изображений, при этом каждый класс разделён приблизительно поровну между тестом и трейном. Все классы уровня параметров _Марка_, _Год_, _Модель_ и др. (например, _2012 Tesla Model S or 2012 BMW M3 coupe_).\n",
    "\n",
    "В нашем же случае в `train` 204 изображения, и в `test` — 202 изображения.\n",
    "\n",
    "## Что делать\n",
    "\n",
    "Помимо данных, потребуется скачать:\n",
    "\n",
    "* [код](https://github.com/ton4eg/coursera_pa), \n",
    "* веса модели [по ссылке](https://yadi.sk/d/9-3kXyxRvnBwh)\n",
    "\n",
    "Положите данные, код и модель в одну папку. У вас должна получиться такая структура:\n",
    "\n",
    "```\n",
    "/assignment-computer-vision/\n",
    "|\n",
    "|-- test              # папки  \n",
    "|    `---- ...        # с\n",
    "|-- train             # картинками\n",
    "|    `---- ...\n",
    "|\n",
    "|-- class_names.txt   # имена классов, номер строки соответствует id класса\n",
    "|-- results.txt       # соответствие имя картинки — id класса\n",
    "|-- vgg16_weights.npz # веса модели в формате tensorflow\n",
    "|\n",
    "|-- vgg16.py            # основной скрипт\n",
    "|-- imagenet_classes.py \n",
    "|\n",
    "`-- beach.jpg         # картиночка с пляжем\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspired by\n",
    "# http://www.cs.toronto.edu/~frossard/post/vgg16/                               \n",
    "# Model from https://gist.github.com/ksimonyan/211839e770f7b538e2d8#file-readme-md     #\n",
    "# Weights from Caffe converted using https://github.com/ethereon/caffe-tensorflow      #\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() \n",
    "import numpy as np\n",
    "from imageio import imread\n",
    "from skimage.transform import resize\n",
    "from imagenet_classes import class_names\n",
    "import sys\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом классе содержится описание модели VGG - структура, инициализация, загрузка весов. Следует помнить - пока не запущена сессия Tensorflow, никакой реальной работы не производится."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class vgg16:\n",
    "    def __init__(self, imgs, weights=None, sess=None):\n",
    "        self.imgs = imgs\n",
    "        self.convlayers()\n",
    "        self.fc_layers()\n",
    "        self.probs = tf.nn.softmax(self.fc3l)\n",
    "        if weights is not None and sess is not None:\n",
    "            self.load_weights(weights, sess)\n",
    "\n",
    "\n",
    "    def convlayers(self):\n",
    "        self.parameters = []\n",
    "\n",
    "        # zero-mean input\n",
    "        with tf.name_scope('preprocess') as scope:\n",
    "            mean = tf.constant([123.68, 116.779, 103.939], dtype=tf.float32, shape=[1, 1, 1, 3], name='img_mean')\n",
    "            images = self.imgs-mean\n",
    "\n",
    "        # conv1_1\n",
    "        with tf.name_scope('conv1_1') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 3, 64], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(images, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[64], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv1_1 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # conv1_2\n",
    "        with tf.name_scope('conv1_2') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 64, 64], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(self.conv1_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[64], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv1_2 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # pool1\n",
    "        self.pool1 = tf.nn.max_pool(self.conv1_2,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME',\n",
    "                               name='pool1')\n",
    "\n",
    "        # conv2_1\n",
    "        with tf.name_scope('conv2_1') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 64, 128], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(self.pool1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[128], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv2_1 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # conv2_2\n",
    "        with tf.name_scope('conv2_2') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 128, 128], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(self.conv2_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[128], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv2_2 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # pool2\n",
    "        self.pool2 = tf.nn.max_pool(self.conv2_2,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME',\n",
    "                               name='pool2')\n",
    "\n",
    "        # conv3_1\n",
    "        with tf.name_scope('conv3_1') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 128, 256], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(self.pool2, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[256], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv3_1 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # conv3_2\n",
    "        with tf.name_scope('conv3_2') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 256, 256], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(self.conv3_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[256], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv3_2 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # conv3_3\n",
    "        with tf.name_scope('conv3_3') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 256, 256], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(self.conv3_2, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[256], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv3_3 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # pool3\n",
    "        self.pool3 = tf.nn.max_pool(self.conv3_3,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME',\n",
    "                               name='pool3')\n",
    "\n",
    "        # conv4_1\n",
    "        with tf.name_scope('conv4_1') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 256, 512], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(self.pool3, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv4_1 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # conv4_2\n",
    "        with tf.name_scope('conv4_2') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(self.conv4_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv4_2 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # conv4_3\n",
    "        with tf.name_scope('conv4_3') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(self.conv4_2, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv4_3 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # pool4\n",
    "        self.pool4 = tf.nn.max_pool(self.conv4_3,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME',\n",
    "                               name='pool4')\n",
    "\n",
    "        # conv5_1\n",
    "        with tf.name_scope('conv5_1') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(self.pool4, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv5_1 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # conv5_2\n",
    "        with tf.name_scope('conv5_2') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(self.conv5_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv5_2 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # conv5_3\n",
    "        with tf.name_scope('conv5_3') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(self.conv5_2, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv5_3 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # pool5\n",
    "        self.pool5 = tf.nn.max_pool(self.conv5_3,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME',\n",
    "                               name='pool4')\n",
    "\n",
    "    def fc_layers(self):\n",
    "        # fc1\n",
    "        with tf.name_scope('fc1') as scope:\n",
    "            shape = int(np.prod(self.pool5.get_shape()[1:]))\n",
    "            fc1w = tf.Variable(tf.truncated_normal([shape, 4096],\n",
    "                                                         dtype=tf.float32,\n",
    "                                                         stddev=1e-1), name='weights')\n",
    "            fc1b = tf.Variable(tf.constant(1.0, shape=[4096], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            pool5_flat = tf.reshape(self.pool5, [-1, shape])\n",
    "            fc1l = tf.nn.bias_add(tf.matmul(pool5_flat, fc1w), fc1b)\n",
    "            self.fc1 = tf.nn.relu(fc1l)\n",
    "            self.parameters += [fc1w, fc1b]\n",
    "\n",
    "        # fc2\n",
    "        with tf.name_scope('fc2') as scope:\n",
    "            fc2w = tf.Variable(tf.truncated_normal([4096, 4096],\n",
    "                                                         dtype=tf.float32,\n",
    "                                                         stddev=1e-1), name='weights')\n",
    "            fc2b = tf.Variable(tf.constant(1.0, shape=[4096], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            fc2l = tf.nn.bias_add(tf.matmul(self.fc1, fc2w), fc2b)\n",
    "            self.fc2 = tf.nn.relu(fc2l)\n",
    "            self.parameters += [fc2w, fc2b]\n",
    "\n",
    "        # fc3\n",
    "        with tf.name_scope('fc3') as scope:\n",
    "            fc3w = tf.Variable(tf.truncated_normal([4096, 1000],\n",
    "                                                         dtype=tf.float32,\n",
    "                                                         stddev=1e-1), name='weights')\n",
    "            fc3b = tf.Variable(tf.constant(1.0, shape=[1000], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            self.fc3l = tf.nn.bias_add(tf.matmul(self.fc2, fc3w), fc3b)\n",
    "            self.parameters += [fc3w, fc3b]\n",
    "\n",
    "    def load_weights(self, weight_file, sess):\n",
    "        weights = np.load(weight_file)\n",
    "        keys = sorted(weights.keys())\n",
    "        for i, k in enumerate(keys):\n",
    "            print(i, k, np.shape(weights[k]))\n",
    "            sess.run(self.parameters[i].assign(weights[k]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция сохранения в файл ответа, состоящего из одного числа\n",
    "def save_answerNum(fname,number):\n",
    "    with open(fname,\"w\") as fout:\n",
    "        fout.write(str(number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция сохранения в файл ответа, представленного массивом\n",
    "def save_answerArray(fname,array):\n",
    "    with open(fname,\"w\") as fout:\n",
    "        fout.write(\" \".join([str(el) for el in array]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка словаря из текстового файла. Словарь у нас используется для сохранения меток классов в выборке data.\n",
    "def load_txt(fname):\n",
    "    line_dict = {}\n",
    "    for line in open(fname):\n",
    "        fname, class_id = line.strip().split()\n",
    "        line_dict[fname] = class_id\n",
    "\n",
    "    return line_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция обработки отдельного изображения, печатает метки TOP-5 классов и уверенность модели в каждом из них.\n",
    "def process_image(fname):\n",
    "    img1 = imread(fname, pilmode='RGB')\n",
    "    img1 = resize(img1, (224, 224))\n",
    "    \n",
    "    prob = sess.run(vgg.probs, feed_dict={vgg.imgs: [img1]})[0]\n",
    "    preds = (np.argsort(prob)[::-1])[0:5]\n",
    "    for p in preds:\n",
    "        print(class_names[p], prob[p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 conv1_1_W (3, 3, 3, 64)\n",
      "1 conv1_1_b (64,)\n",
      "2 conv1_2_W (3, 3, 64, 64)\n",
      "3 conv1_2_b (64,)\n",
      "4 conv2_1_W (3, 3, 64, 128)\n",
      "5 conv2_1_b (128,)\n",
      "6 conv2_2_W (3, 3, 128, 128)\n",
      "7 conv2_2_b (128,)\n",
      "8 conv3_1_W (3, 3, 128, 256)\n",
      "9 conv3_1_b (256,)\n",
      "10 conv3_2_W (3, 3, 256, 256)\n",
      "11 conv3_2_b (256,)\n",
      "12 conv3_3_W (3, 3, 256, 256)\n",
      "13 conv3_3_b (256,)\n",
      "14 conv4_1_W (3, 3, 256, 512)\n",
      "15 conv4_1_b (512,)\n",
      "16 conv4_2_W (3, 3, 512, 512)\n",
      "17 conv4_2_b (512,)\n",
      "18 conv4_3_W (3, 3, 512, 512)\n",
      "19 conv4_3_b (512,)\n",
      "20 conv5_1_W (3, 3, 512, 512)\n",
      "21 conv5_1_b (512,)\n",
      "22 conv5_2_W (3, 3, 512, 512)\n",
      "23 conv5_2_b (512,)\n",
      "24 conv5_3_W (3, 3, 512, 512)\n",
      "25 conv5_3_b (512,)\n",
      "26 fc6_W (25088, 4096)\n",
      "27 fc6_b (4096,)\n",
      "28 fc7_W (4096, 4096)\n",
      "29 fc7_b (4096,)\n",
      "30 fc8_W (4096, 1000)\n",
      "31 fc8_b (1000,)\n"
     ]
    }
   ],
   "source": [
    "# Инициируем TF сессию, и инициализируем модель. На этом шаге модель загружает веса. Веса - это 500Мб в сжатом виде\n",
    "# и ~2.5Гб в памяти, процесс их загрузки послойно выводится ниже этой ячейки, и если вы увидите этот вывод ещё раз - \n",
    "# у вас неистово кончается память. Остановитесь. Также, не запускайте эту ячейку на выполнение больше одного раза\n",
    "# за запуск ядра Jupyter.\n",
    "sess = tf.Session()\n",
    "imgs = tf.placeholder(tf.float32, [None, 224, 224, 3])\n",
    "vgg = vgg16(imgs, 'vgg16_weights.npz', sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все ячейки выше не нуждаются в модификации для выполнения задания, и необходимы к исполнению только один раз, в порядке следования. Повторный запуск ячейки с инициализацией модели будет сжирать память. Вы предупреждены."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1\\. \n",
    "\n",
    "Для начала нужно запустить готовую модель `vgg16`, предобученную на `imagenet`. Модель обучена с помощью `caffe` и сконвертирована в формат `tensorflow` - `vgg16_weights.npz`. Скрипт, иллюстрирующий применение этой модели к изображению, возвращает топ-5 классов из `imagenet` и уверенность в этих классах.\n",
    "\n",
    "**Задание:** Загрузите уверенность для первого класса для изображения `train/00002.jpg` с точностью до 1 знака после запятой в файл с ответом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matchstick 0.0755118\n",
      "nematode, nematode worm, roundworm 0.049533345\n",
      "lighter, light, igniter, ignitor 0.030237619\n",
      "digital clock 0.029393025\n",
      "spotlight, spot 0.023299297\n"
     ]
    }
   ],
   "source": [
    "process_image(\"train/00002.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_answerNum(\"vgg16_answer1.txt\", 0.1 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2\\. \n",
    "\n",
    "Научитесь извлекать `fc2` слой. Возьмите за основу код `process_image`, и модифицируйте, чтобы вместо последнего слоя извлекались выходы `fc2`.\n",
    "\n",
    "**Задание:** Посчитайте `fc2` для картинки `train/00002.jpg`.  Запишите первые 20 компонент."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = imread('data/train/00002.jpg', pilmode='RGB')\n",
    "img1 = resize(img1, (224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00000000e+00,  3.87282073e-01,  2.26503164e-01,  9.10455465e-01,\n",
       "        1.17599964e-04, -0.00000000e+00,  1.11121798e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00,  1.40186787e-01, -0.00000000e+00,\n",
       "        2.30205464e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = sess.run(vgg.fc2, feed_dict={vgg.imgs: [img1]})[0]\n",
    "prob[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_answerArray(\"vgg16_answer2.txt\", prob[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3\\. \n",
    "\n",
    "Теперь необходимо дообучить классификатор на нашей базе. В качестве бейзлайна предлагается воспользоваться классификатором `svm` из пакета `scipy`.\n",
    "\n",
    "- Модифицировать функцию `get_features` и добавить возможность вычислять `fc2`. (Аналогично второму заданию).\n",
    "- Применить `get_feautures`, чтобы получить `X_test` и `Y_test`.\n",
    "- Воспользоваться классификатором `SVC` с `random_state=0`.\n",
    "\n",
    "> **Важно!** Если вам не удалось поставить `tensorflow`, то необходимо вместо использования функции `get_features`, загрузить предпосчитанные `X`, `Y`, `X_test`, `Y_test` из архива: https://yadi.sk/d/RzMOK8Fjvs6Ln и воспользоваться функцией `np.load` для их загрузки, а после этого два последних пункта.\n",
    "\n",
    "**Задание:** Сколько правильных ответов получается на валидационной выборке из папки `test`? Запишите в файл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция, возвращающая признаковое описание для каждого файла jpg в заданной папке\n",
    "def get_features(folder, ydict):\n",
    "\n",
    "    paths = glob.glob(folder)\n",
    "    X = np.zeros((len(paths), 4096))\n",
    "    Y = np.zeros(len(paths))\n",
    "\n",
    "    for i,img_name in enumerate(paths):\n",
    "        np.random.seed(0)\n",
    "        print(img_name)\n",
    "        base = os.path.basename(img_name)\n",
    "        Y[i] = ydict[base]\n",
    "\n",
    "        img1 = imread(img_name, pilmode='RGB')\n",
    "        img1 = resize(img1, (224, 224))\n",
    "        fc2 = sess.run(vgg.fc2, feed_dict={vgg.imgs: [img1]})[0]\n",
    "        \n",
    "        \n",
    "        X[i, :] = fc2\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция обработки папки. Ожидается, что в этой папке лежит файл results.txt с метками классов, и \n",
    "# имеются подразделы train и test с jpg файлами.\n",
    "def process_folder(folder):\n",
    "    ydict = load_txt(os.path.join(folder,'results.txt'))\n",
    "    np.random.seed(0)\n",
    "    X, Y = get_features(os.path.join(folder, 'train/*jpg'), ydict)\n",
    "    # Ваш код здесь. \n",
    "    X_test, Y_test = get_features(os.path.join(folder, 'test/*jpg'), ydict)\n",
    "\n",
    "    # Ваш код здесь. \n",
    "    np.random.seed(0)\n",
    "    clf = SVC()\n",
    "    clf.fit(X, Y)\n",
    "    \n",
    "    Y_test_pred = clf.predict(X_test)\n",
    "    res = sum(Y_test == Y_test_pred) # Число правильно предсказанных классов\n",
    "    print(res)\n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\train\\00002.jpg\n",
      ".\\train\\00065.jpg\n",
      ".\\train\\00069.jpg\n",
      ".\\train\\00081.jpg\n",
      ".\\train\\00150.jpg\n",
      ".\\train\\00151.jpg\n",
      ".\\train\\00163.jpg\n",
      ".\\train\\00198.jpg\n",
      ".\\train\\00208.jpg\n",
      ".\\train\\00221.jpg\n",
      ".\\train\\00236.jpg\n",
      ".\\train\\00244.jpg\n",
      ".\\train\\00255.jpg\n",
      ".\\train\\00292.jpg\n",
      ".\\train\\00308.jpg\n",
      ".\\train\\00320.jpg\n",
      ".\\train\\00340.jpg\n",
      ".\\train\\00370.jpg\n",
      ".\\train\\00374.jpg\n",
      ".\\train\\00392.jpg\n",
      ".\\train\\00405.jpg\n",
      ".\\train\\00410.jpg\n",
      ".\\train\\00424.jpg\n",
      ".\\train\\00425.jpg\n",
      ".\\train\\00462.jpg\n",
      ".\\train\\00503.jpg\n",
      ".\\train\\00522.jpg\n",
      ".\\train\\00631.jpg\n",
      ".\\train\\00634.jpg\n",
      ".\\train\\00635.jpg\n",
      ".\\train\\00670.jpg\n",
      ".\\train\\00691.jpg\n",
      ".\\train\\00697.jpg\n",
      ".\\train\\00700.jpg\n",
      ".\\train\\00707.jpg\n",
      ".\\train\\00740.jpg\n",
      ".\\train\\00742.jpg\n",
      ".\\train\\00773.jpg\n",
      ".\\train\\00858.jpg\n",
      ".\\train\\00878.jpg\n",
      ".\\train\\00880.jpg\n",
      ".\\train\\00887.jpg\n",
      ".\\train\\00898.jpg\n",
      ".\\train\\00912.jpg\n",
      ".\\train\\00920.jpg\n",
      ".\\train\\00946.jpg\n",
      ".\\train\\01010.jpg\n",
      ".\\train\\01012.jpg\n",
      ".\\train\\01031.jpg\n",
      ".\\train\\01034.jpg\n",
      ".\\train\\01105.jpg\n",
      ".\\train\\01134.jpg\n",
      ".\\train\\01148.jpg\n",
      ".\\train\\01186.jpg\n",
      ".\\train\\01214.jpg\n",
      ".\\train\\01255.jpg\n",
      ".\\train\\01264.jpg\n",
      ".\\train\\01276.jpg\n",
      ".\\train\\01277.jpg\n",
      ".\\train\\01283.jpg\n",
      ".\\train\\01322.jpg\n",
      ".\\train\\01331.jpg\n",
      ".\\train\\01361.jpg\n",
      ".\\train\\01392.jpg\n",
      ".\\train\\01413.jpg\n",
      ".\\train\\01416.jpg\n",
      ".\\train\\01468.jpg\n",
      ".\\train\\01483.jpg\n",
      ".\\train\\01506.jpg\n",
      ".\\train\\01535.jpg\n",
      ".\\train\\01537.jpg\n",
      ".\\train\\01617.jpg\n",
      ".\\train\\01661.jpg\n",
      ".\\train\\01678.jpg\n",
      ".\\train\\01680.jpg\n",
      ".\\train\\01705.jpg\n",
      ".\\train\\01706.jpg\n",
      ".\\train\\01716.jpg\n",
      ".\\train\\01750.jpg\n",
      ".\\train\\01768.jpg\n",
      ".\\train\\01786.jpg\n",
      ".\\train\\01819.jpg\n",
      ".\\train\\01832.jpg\n",
      ".\\train\\01852.jpg\n",
      ".\\train\\01864.jpg\n",
      ".\\train\\01870.jpg\n",
      ".\\train\\01891.jpg\n",
      ".\\train\\01901.jpg\n",
      ".\\train\\01911.jpg\n",
      ".\\train\\01918.jpg\n",
      ".\\train\\01952.jpg\n",
      ".\\train\\01972.jpg\n",
      ".\\train\\02004.jpg\n",
      ".\\train\\02050.jpg\n",
      ".\\train\\02058.jpg\n",
      ".\\train\\02065.jpg\n",
      ".\\train\\02095.jpg\n",
      ".\\train\\02111.jpg\n",
      ".\\train\\02124.jpg\n",
      ".\\train\\02145.jpg\n",
      ".\\train\\02194.jpg\n",
      ".\\train\\02240.jpg\n",
      ".\\train\\02274.jpg\n",
      ".\\train\\02286.jpg\n",
      ".\\train\\02305.jpg\n",
      ".\\train\\02311.jpg\n",
      ".\\train\\02314.jpg\n",
      ".\\train\\02326.jpg\n",
      ".\\train\\02359.jpg\n",
      ".\\train\\02363.jpg\n",
      ".\\train\\02364.jpg\n",
      ".\\train\\02377.jpg\n",
      ".\\train\\02378.jpg\n",
      ".\\train\\02438.jpg\n",
      ".\\train\\02457.jpg\n",
      ".\\train\\02484.jpg\n",
      ".\\train\\02491.jpg\n",
      ".\\train\\02540.jpg\n",
      ".\\train\\02577.jpg\n",
      ".\\train\\02589.jpg\n",
      ".\\train\\02594.jpg\n",
      ".\\train\\02605.jpg\n",
      ".\\train\\02645.jpg\n",
      ".\\train\\02663.jpg\n",
      ".\\train\\02669.jpg\n",
      ".\\train\\02670.jpg\n",
      ".\\train\\02671.jpg\n",
      ".\\train\\02738.jpg\n",
      ".\\train\\02739.jpg\n",
      ".\\train\\02771.jpg\n",
      ".\\train\\02832.jpg\n",
      ".\\train\\02843.jpg\n",
      ".\\train\\02848.jpg\n",
      ".\\train\\02897.jpg\n",
      ".\\train\\02911.jpg\n",
      ".\\train\\02913.jpg\n",
      ".\\train\\02919.jpg\n",
      ".\\train\\02993.jpg\n",
      ".\\train\\03008.jpg\n",
      ".\\train\\03009.jpg\n",
      ".\\train\\03011.jpg\n",
      ".\\train\\03030.jpg\n",
      ".\\train\\03051.jpg\n",
      ".\\train\\03054.jpg\n",
      ".\\train\\03064.jpg\n",
      ".\\train\\03081.jpg\n",
      ".\\train\\03101.jpg\n",
      ".\\train\\03102.jpg\n",
      ".\\train\\03127.jpg\n",
      ".\\train\\03152.jpg\n",
      ".\\train\\03165.jpg\n",
      ".\\train\\03169.jpg\n",
      ".\\train\\03191.jpg\n",
      ".\\train\\03238.jpg\n",
      ".\\train\\03239.jpg\n",
      ".\\train\\03241.jpg\n",
      ".\\train\\03243.jpg\n",
      ".\\train\\03265.jpg\n",
      ".\\train\\03267.jpg\n",
      ".\\train\\03308.jpg\n",
      ".\\train\\03311.jpg\n",
      ".\\train\\03316.jpg\n",
      ".\\train\\03317.jpg\n",
      ".\\train\\03379.jpg\n",
      ".\\train\\03390.jpg\n",
      ".\\train\\03393.jpg\n",
      ".\\train\\03417.jpg\n",
      ".\\train\\03454.jpg\n",
      ".\\train\\03467.jpg\n",
      ".\\train\\03511.jpg\n",
      ".\\train\\03512.jpg\n",
      ".\\train\\03523.jpg\n",
      ".\\train\\03537.jpg\n",
      ".\\train\\03575.jpg\n",
      ".\\train\\03589.jpg\n",
      ".\\train\\03607.jpg\n",
      ".\\train\\03608.jpg\n",
      ".\\train\\03641.jpg\n",
      ".\\train\\03659.jpg\n",
      ".\\train\\03662.jpg\n",
      ".\\train\\03670.jpg\n",
      ".\\train\\03690.jpg\n",
      ".\\train\\03715.jpg\n",
      ".\\train\\03732.jpg\n",
      ".\\train\\03761.jpg\n",
      ".\\train\\03767.jpg\n",
      ".\\train\\03772.jpg\n",
      ".\\train\\03790.jpg\n",
      ".\\train\\03795.jpg\n",
      ".\\train\\03813.jpg\n",
      ".\\train\\03828.jpg\n",
      ".\\train\\03854.jpg\n",
      ".\\train\\03871.jpg\n",
      ".\\train\\03875.jpg\n",
      ".\\train\\03877.jpg\n",
      ".\\train\\03881.jpg\n",
      ".\\train\\03943.jpg\n",
      ".\\train\\03965.jpg\n",
      ".\\train\\03968.jpg\n",
      ".\\train\\04011.jpg\n",
      ".\\train\\04056.jpg\n",
      ".\\train\\04072.jpg\n",
      ".\\train\\04085.jpg\n",
      ".\\train\\04121.jpg\n",
      ".\\test\\04186.jpg\n",
      ".\\test\\04190.jpg\n",
      ".\\test\\04197.jpg\n",
      ".\\test\\04216.jpg\n",
      ".\\test\\04224.jpg\n",
      ".\\test\\04244.jpg\n",
      ".\\test\\04247.jpg\n",
      ".\\test\\04252.jpg\n",
      ".\\test\\04308.jpg\n",
      ".\\test\\04338.jpg\n",
      ".\\test\\04349.jpg\n",
      ".\\test\\04386.jpg\n",
      ".\\test\\04392.jpg\n",
      ".\\test\\04396.jpg\n",
      ".\\test\\04470.jpg\n",
      ".\\test\\04482.jpg\n",
      ".\\test\\04484.jpg\n",
      ".\\test\\04486.jpg\n",
      ".\\test\\04493.jpg\n",
      ".\\test\\04494.jpg\n",
      ".\\test\\04495.jpg\n",
      ".\\test\\04509.jpg\n",
      ".\\test\\04510.jpg\n",
      ".\\test\\04511.jpg\n",
      ".\\test\\04544.jpg\n",
      ".\\test\\04552.jpg\n",
      ".\\test\\04578.jpg\n",
      ".\\test\\04588.jpg\n",
      ".\\test\\04608.jpg\n",
      ".\\test\\04631.jpg\n",
      ".\\test\\04651.jpg\n",
      ".\\test\\04669.jpg\n",
      ".\\test\\04691.jpg\n",
      ".\\test\\04724.jpg\n",
      ".\\test\\04725.jpg\n",
      ".\\test\\04750.jpg\n",
      ".\\test\\04816.jpg\n",
      ".\\test\\04825.jpg\n",
      ".\\test\\04827.jpg\n",
      ".\\test\\04833.jpg\n",
      ".\\test\\04874.jpg\n",
      ".\\test\\04884.jpg\n",
      ".\\test\\04892.jpg\n",
      ".\\test\\04942.jpg\n",
      ".\\test\\05023.jpg\n",
      ".\\test\\05030.jpg\n",
      ".\\test\\05042.jpg\n",
      ".\\test\\05048.jpg\n",
      ".\\test\\05052.jpg\n",
      ".\\test\\05057.jpg\n",
      ".\\test\\05077.jpg\n",
      ".\\test\\05125.jpg\n",
      ".\\test\\05128.jpg\n",
      ".\\test\\05143.jpg\n",
      ".\\test\\05197.jpg\n",
      ".\\test\\05224.jpg\n",
      ".\\test\\05259.jpg\n",
      ".\\test\\05261.jpg\n",
      ".\\test\\05281.jpg\n",
      ".\\test\\05295.jpg\n",
      ".\\test\\05304.jpg\n",
      ".\\test\\05306.jpg\n",
      ".\\test\\05307.jpg\n",
      ".\\test\\05324.jpg\n",
      ".\\test\\05333.jpg\n",
      ".\\test\\05347.jpg\n",
      ".\\test\\05349.jpg\n",
      ".\\test\\05366.jpg\n",
      ".\\test\\05373.jpg\n",
      ".\\test\\05382.jpg\n",
      ".\\test\\05386.jpg\n",
      ".\\test\\05405.jpg\n",
      ".\\test\\05434.jpg\n",
      ".\\test\\05534.jpg\n",
      ".\\test\\05545.jpg\n",
      ".\\test\\05567.jpg\n",
      ".\\test\\05579.jpg\n",
      ".\\test\\05657.jpg\n",
      ".\\test\\05671.jpg\n",
      ".\\test\\05694.jpg\n",
      ".\\test\\05718.jpg\n",
      ".\\test\\05748.jpg\n",
      ".\\test\\05754.jpg\n",
      ".\\test\\05804.jpg\n",
      ".\\test\\05821.jpg\n",
      ".\\test\\05909.jpg\n",
      ".\\test\\05916.jpg\n",
      ".\\test\\05918.jpg\n",
      ".\\test\\05921.jpg\n",
      ".\\test\\05930.jpg\n",
      ".\\test\\05967.jpg\n",
      ".\\test\\05979.jpg\n",
      ".\\test\\06002.jpg\n",
      ".\\test\\06024.jpg\n",
      ".\\test\\06052.jpg\n",
      ".\\test\\06061.jpg\n",
      ".\\test\\06099.jpg\n",
      ".\\test\\06145.jpg\n",
      ".\\test\\06158.jpg\n",
      ".\\test\\06159.jpg\n",
      ".\\test\\06174.jpg\n",
      ".\\test\\06179.jpg\n",
      ".\\test\\06183.jpg\n",
      ".\\test\\06196.jpg\n",
      ".\\test\\06206.jpg\n",
      ".\\test\\06239.jpg\n",
      ".\\test\\06244.jpg\n",
      ".\\test\\06262.jpg\n",
      ".\\test\\06269.jpg\n",
      ".\\test\\06292.jpg\n",
      ".\\test\\06296.jpg\n",
      ".\\test\\06302.jpg\n",
      ".\\test\\06309.jpg\n",
      ".\\test\\06313.jpg\n",
      ".\\test\\06328.jpg\n",
      ".\\test\\06375.jpg\n",
      ".\\test\\06381.jpg\n",
      ".\\test\\06388.jpg\n",
      ".\\test\\06406.jpg\n",
      ".\\test\\06422.jpg\n",
      ".\\test\\06453.jpg\n",
      ".\\test\\06480.jpg\n",
      ".\\test\\06485.jpg\n",
      ".\\test\\06516.jpg\n",
      ".\\test\\06518.jpg\n",
      ".\\test\\06530.jpg\n",
      ".\\test\\06538.jpg\n",
      ".\\test\\06539.jpg\n",
      ".\\test\\06571.jpg\n",
      ".\\test\\06603.jpg\n",
      ".\\test\\06614.jpg\n",
      ".\\test\\06624.jpg\n",
      ".\\test\\06644.jpg\n",
      ".\\test\\06660.jpg\n",
      ".\\test\\06675.jpg\n",
      ".\\test\\06683.jpg\n",
      ".\\test\\06718.jpg\n",
      ".\\test\\06751.jpg\n",
      ".\\test\\06771.jpg\n",
      ".\\test\\06774.jpg\n",
      ".\\test\\06782.jpg\n",
      ".\\test\\06784.jpg\n",
      ".\\test\\06816.jpg\n",
      ".\\test\\06832.jpg\n",
      ".\\test\\06833.jpg\n",
      ".\\test\\06839.jpg\n",
      ".\\test\\06850.jpg\n",
      ".\\test\\06896.jpg\n",
      ".\\test\\06906.jpg\n",
      ".\\test\\06921.jpg\n",
      ".\\test\\06974.jpg\n",
      ".\\test\\07025.jpg\n",
      ".\\test\\07050.jpg\n",
      ".\\test\\07061.jpg\n",
      ".\\test\\07121.jpg\n",
      ".\\test\\07169.jpg\n",
      ".\\test\\07171.jpg\n",
      ".\\test\\07174.jpg\n",
      ".\\test\\07175.jpg\n",
      ".\\test\\07191.jpg\n",
      ".\\test\\07214.jpg\n",
      ".\\test\\07278.jpg\n",
      ".\\test\\07279.jpg\n",
      ".\\test\\07290.jpg\n",
      ".\\test\\07346.jpg\n",
      ".\\test\\07351.jpg\n",
      ".\\test\\07364.jpg\n",
      ".\\test\\07386.jpg\n",
      ".\\test\\07392.jpg\n",
      ".\\test\\07445.jpg\n",
      ".\\test\\07450.jpg\n",
      ".\\test\\07463.jpg\n",
      ".\\test\\07471.jpg\n",
      ".\\test\\07483.jpg\n",
      ".\\test\\07487.jpg\n",
      ".\\test\\07599.jpg\n",
      ".\\test\\07661.jpg\n",
      ".\\test\\07663.jpg\n",
      ".\\test\\07666.jpg\n",
      ".\\test\\07684.jpg\n",
      ".\\test\\07696.jpg\n",
      ".\\test\\07704.jpg\n",
      ".\\test\\07706.jpg\n",
      ".\\test\\07752.jpg\n",
      ".\\test\\07769.jpg\n",
      ".\\test\\07800.jpg\n",
      ".\\test\\07833.jpg\n",
      ".\\test\\07860.jpg\n",
      ".\\test\\07897.jpg\n",
      ".\\test\\07916.jpg\n",
      ".\\test\\07960.jpg\n",
      ".\\test\\07966.jpg\n",
      ".\\test\\08005.jpg\n",
      ".\\test\\08011.jpg\n",
      ".\\test\\08016.jpg\n",
      ".\\test\\08018.jpg\n",
      ".\\test\\08031.jpg\n",
      ".\\test\\08044.jpg\n",
      ".\\test\\08085.jpg\n",
      ".\\test\\08096.jpg\n",
      ".\\test\\08127.jpg\n",
      ".\\test\\08133.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\CodingForPython\\Anaconda\\envs\\py37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "answer_3 = process_folder('.') # Вызови меня! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_answerNum(\"vgg16_answer3.txt\", answer_3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
