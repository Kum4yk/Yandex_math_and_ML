{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом задании вам предлагается начать разбираться с задачей анализа тональности отзывов на примере сентимент-анализа отзывов на фильмы.\n",
    "\n",
    "Мы будем использовать стандартный датасет из nltk, уже возникавший в одном из примеров в предыдущих курсах. \n",
    "\n",
    "Для того, чтобы импортировать необходимый модуль, напишите:  \n",
    "<br><center><code>from nltk.corpus import movie_reviews</code></center></br>\n",
    "\n",
    "Чтобы получить id-шники негативных и позитивных отзывов:  \n",
    "<br><center><code>negids = movie_reviews.fileids('neg')\n",
    "posids = movie_reviews.fileids('pos')</code></center></br>\n",
    "  \n",
    "Чтобы получить список негативных отзывов:   \n",
    "<br><center><code>negfeats = [movie_reviews.words(fileids=[f]) for f in negids]</code></center></br>\n",
    "\n",
    "\n",
    "**Инструкция по выполнению**\n",
    "\n",
    "В некоторых пунктах нужно получить ответ - число или строку, которые будет нужно набирать в текстовых файлах и прикреплять в ответах на вопросы. Десятичные дроби записывайте через точку.\n",
    "\n",
    "1. Создайте список из текстов всех имеющихся отзывов, а также список с классами, которые будет использовать ваш классификатор - 0 для негативных отзывов и 1 для позитивных.\n",
    "\n",
    "\n",
    "2. Подсчитайте количество отзывов в выборке.\n",
    "\n",
    "\n",
    "3. Подсчитайте долю класса 1 в выборке.\n",
    "\n",
    "\n",
    "4. Импортируйте CountVectorizer из sklearn.feature_extraction.text. Попробуйте использовать его с настройками по умолчанию для того, чтобы получить признаковое представление каждого текста. Скорее всего, попытка не увенчается успехом. Разберитесь, в чем причина, и добейтесь того, чтобы метод fit_transform у CountVectorizer успешно отрабатывал. Подсчитайте количество признаков в CountVectorizer. Никакой предварительной обработки текста (удаление стоп-слов, нормализация слов) на этом шаге делать не надо, в качестве признаков должны использоваться частоты слов.\n",
    "\n",
    "\n",
    "5. Соберите pipeline из CountVectorizer и LogisticRegression c настройками по-умолчанию и с помощью cross_val_score (также со стандартными настройками) оцените получаемое \"из коробки\" качество по accuracy.\n",
    "\n",
    "\n",
    "6. Аналогично accuracy, оцените качество по ROC AUC.\n",
    "\n",
    "\n",
    "7. Обучите логистическую регрессию на всей доступной вам выборке и выведите 5 наиболее важных для модели признаков (подумайте, какие именно признаки стоит считать такими). Вам могут пригодиться метод get_feature_names() или поле vocabulary_ у класса CountVectorizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вопросы:\n",
    "1. Количество отзывов во всей выборке\n",
    "2. Доля позитивных отзывов\n",
    "3. Количество признаков со стандартными настройками\n",
    "4. Accuracy в кросс-валидации\n",
    "5. ROC AUC в кросс-валидации\n",
    "6. Запишите соответствующие двум самым важным для модели признакам слова из словаря через пробел"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download(\"movie_reviews\")\n",
    "from nltk.corpus import movie_reviews\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_ans(file_name, *args):\n",
    "    with open(file_name, \"w\") as file:\n",
    "        file.write(\" \".join(map(str, args)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 2 3'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(map(str, [1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "negids = movie_reviews.fileids('neg')\n",
    "posids = movie_reviews.fileids('pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Количество отзывов во всей выборке\n",
    "ans_1 = len(negids) + len(posids)\n",
    "write_ans(\"ans_1.txt\", ans_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Доля позитивных отзывов\n",
    "write_ans(\"ans_2.txt\", len(posids) / ans_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "negfeats = [\" \". join(movie_reviews.words(fileids=[f])) for f in negids]\n",
    "posfeats = [\" \". join(movie_reviews.words(fileids=[f])) for f in posids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = negfeats + posfeats\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = [0] * 1000 + [1] * 1000\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39659\n"
     ]
    }
   ],
   "source": [
    "# 3.Количество признаков со стандартными настройками\n",
    "ans_3 = len(clf.get_feature_names())\n",
    "write_ans(\"ans_3.txt\", ans_3)\n",
    "print(ans_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline([(\"vectorizer\", CountVectorizer()), (\"classifier\", LogisticRegression())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4\n",
    "# Соберите pipeline из CountVectorizer и LogisticRegression c настройками по-умолчанию\n",
    "# и с помощью cross_val_score (также со стандартными настройками)\n",
    "# оцените получаемое \"из коробки\" качество по accuracy.\n",
    "\n",
    "count = CountVectorizer()\n",
    "log_reg = LogisticRegression()\n",
    "pipe = Pipeline([('countvectorizer', count),\n",
    "                 ('logisticregression', log_reg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\py36_R\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "D:\\Anaconda3\\envs\\py36_R\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81437126 0.84684685 0.84684685]\n"
     ]
    }
   ],
   "source": [
    "res = cross_val_score(pipe, x, y, scoring=\"accuracy\")\n",
    "print(res)\n",
    "write_ans(\"ans_4.txt\", res.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\py36_R\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "D:\\Anaconda3\\envs\\py36_R\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9006239  0.91283175 0.91887383]\n"
     ]
    }
   ],
   "source": [
    "# 5. ROC AUC в кросс-валидации\n",
    "\n",
    "res = cross_val_score(pipe, x, y, scoring=\"roc_auc\")\n",
    "write_ans(\"ans_5.txt\", res.mean())\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6\n",
    "# Запишите соответствующие двум самым важным для модели признакам слова из словаря через пробел\n",
    "\n",
    "pipe.fit(x, y);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.13388312e-02, -1.78986913e-02,  2.67552873e-06, ...,\n",
       "       -7.15693483e-03,  3.78870960e-04, -1.40824162e-03])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = sorted(\n",
    "    list(\n",
    "        zip(\n",
    "            abs(log_reg.coef_[0]),\n",
    "            count.get_feature_names()\n",
    "            )\n",
    "        ),\n",
    "    reverse=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.7822542657559508, 'bad'),\n",
       " (0.6366239815648874, 'unfortunately'),\n",
       " (0.5928385063136231, 'worst'),\n",
       " (0.5560509781124982, 'fun'),\n",
       " (0.5081911925070863, 'waste')]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bad', 'unfortunately']\n"
     ]
    }
   ],
   "source": [
    "ans = [x[1] for x in features[:2]]\n",
    "print(ans)\n",
    "write_ans(\"ans_6.txt\", *ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bad', 'unfortunately', 'worst', 'waste', 'nothing']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs = log_reg.coef_[0]\n",
    "[count.get_feature_names()[list(coeffs).index(i)] for i in sorted(coeffs)[:5]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
