{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "grNXGYfnXroY",
    "outputId": "d4065ca4-c8a8-41b6-d256-d7a4720f17e9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import functional as F\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xgimtDPmck6_",
    "outputId": "36bdad33-0c6b-456a-8fa6-d400f515dab6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xRnKCXXEZUIZ",
    "outputId": "de4e1478-b9f8-4dc3-f66b-aab09825fa3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ufzPdoTtNikq"
   },
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OESFSMm4Lac_"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/content/gdrive/My Drive/sentiment_analysis_on_movie_reviews/products_sentiment_train.tsv', sep = '\\t', header = None, names = ['text', 'y'])\n",
    "test = pd.read_csv('/content/gdrive/My Drive/sentiment_analysis_on_movie_reviews/products_sentiment_test.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "UQctO6lCMkUA",
    "outputId": "ec7b1a22-53e8-4b13-de32-89af827341bd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 . take around 10,000 640x480 pictures .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i downloaded a trial version of computer assoc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the wrt54g plus the hga7t is a perfect solutio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i dont especially like how music files are uns...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i was using the cheapie pail ... and it worked...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  y\n",
       "0          2 . take around 10,000 640x480 pictures .  1\n",
       "1  i downloaded a trial version of computer assoc...  1\n",
       "2  the wrt54g plus the hga7t is a perfect solutio...  1\n",
       "3  i dont especially like how music files are uns...  0\n",
       "4  i was using the cheapie pail ... and it worked...  1"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "F05bCZsmXrou",
    "outputId": "70f0673b-cf3c-43bc-928f-e8ee5aac6d59"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>so , why the small digital elph , rather than ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3/4 way through the first disk we played on it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>better for the zen micro is outlook compatibil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6 . play gameboy color games on it with goboy .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>likewise , i 've heard norton 2004 professiona...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                               text\n",
       "0   0  so , why the small digital elph , rather than ...\n",
       "1   1  3/4 way through the first disk we played on it...\n",
       "2   2  better for the zen micro is outlook compatibil...\n",
       "3   3    6 . play gameboy color games on it with goboy .\n",
       "4   4  likewise , i 've heard norton 2004 professiona..."
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "UH8SzUxcOMjY",
    "outputId": "391608b9-86c6-4a0c-f2b2-b1a2f87290ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1274\n",
       "0     726\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "id": "LtJPh9uLcAA0",
    "outputId": "e49b15c3-a1b1-44e3-cae1-e211a0c2b384"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f190ed53588>"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(train.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "colab_type": "code",
    "id": "UIRbd1tMcZVj",
    "outputId": "2d05f41e-a79a-4527-bf48-75f00ad1b107"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    2000 non-null   object\n",
      " 1   y       2000 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 31.4+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9aHyGuTFgyPO"
   },
   "source": [
    "## Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "unFNhRr5iJxA"
   },
   "source": [
    "### Data Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "78iSu7mX7PVH",
    "outputId": "e3226c4f-c0f4-4fe9-9e2e-eaeb4720eb7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.metrics.scores import precision, recall, f_measure\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "72ne4Yhp66kf"
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = BeautifulSoup(text).get_text()\n",
    "    text = re.sub('[^a-zA-Zа-яА-Я1-9]+', ' ', text)\n",
    "    text = re.sub('@[^\\s]+', 'USER', text)\n",
    "    text = text.lower().replace('ё', 'е')\n",
    "    words = word_tokenize(text)\n",
    "    lemma_words = [lemmatizer.lemmatize(i) for i in words]\n",
    "    return lemma_words\n",
    "\n",
    "def preprocess_for_lang(data):\n",
    "    text = [preprocess_text(t) for t in data['text']]\n",
    "    \n",
    "    return pd.Series(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j8n3GOE0UFNu"
   },
   "outputs": [],
   "source": [
    "text = preprocess_for_lang(train)\n",
    "labels = train['y']\n",
    "\n",
    "test_text = preprocess_for_lang(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "id": "7W4nKp8MqmR9",
    "outputId": "00089935-0164-4084-d758-83fad95f321c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [so, why, the, small, digital, elph, rather, t...\n",
       "1      [3, 4, way, through, the, first, disk, we, pla...\n",
       "2      [better, for, the, zen, micro, is, outlook, co...\n",
       "3      [6, play, gameboy, color, game, on, it, with, ...\n",
       "4      [likewise, i, ve, heard, norton, 2, 4, profess...\n",
       "                             ...                        \n",
       "495    [i, took, perfect, care, of, this, player, and...\n",
       "496                 [it, s, a, very, intuitive, program]\n",
       "497    [the, only, drawback, is, the, viewfinder, is,...\n",
       "498    [it, film, 1, second, video, for, cry, out, loud]\n",
       "499                     [everything, shine, of, quality]\n",
       "Length: 500, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iykbHJO1jzEP"
   },
   "source": [
    "### Data Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J4J0FyGQjVci"
   },
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "\n",
    "import transformers as ppb\n",
    "\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model_bert = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oehwRs9pWeYc"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def text_to_hidden_states(tokenizer, model, X):\n",
    "\n",
    "    tokenized = X.apply(lambda x: tokenizer.encode(x, add_special_tokens = True))\n",
    "    max_len = 0\n",
    "\n",
    "    for i in tokenized.values:\n",
    "        if len(i) > max_len:\n",
    "          max_len = len(i)\n",
    "\n",
    "    padded = np.array([i + [0] * (max_len - len(i)) for i in tokenized.values])\n",
    "\n",
    "    attention_mask = torch.tensor(np.where(padded != 0, 1, 0))\n",
    "    input_ids = torch.tensor(padded).to(torch.int64) \n",
    "\n",
    "    with torch.no_grad():\n",
    "        last_hidden_states = model(input_ids, attention_mask = attention_mask)\n",
    "\n",
    "    return last_hidden_states[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TVgiby7zoWto"
   },
   "outputs": [],
   "source": [
    "def hidden(tokenizer, model, X_train, X_val, X_test, y_train, y_val):\n",
    "\n",
    "    X_train = text_to_hidden_states(tokenizer, model, X_train)\n",
    "    X_val = text_to_hidden_states(tokenizer, model, X_val)\n",
    "    X_test = text_to_hidden_states(tokenizer, model, X_test)\n",
    "\n",
    "    y_train = torch.from_numpy(np.array(y_train).astype(int))\n",
    "    y_val = torch.from_numpy(np.array(y_val).astype(int))\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b0XyUVrTrVpV"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(text, labels, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9REE1MSWLh8A"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val = hidden(tokenizer, model_bert, X_train, X_val, test_text, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B_eOlzWTn_Bm"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OVIpJ4-p-Z1h"
   },
   "outputs": [],
   "source": [
    "class CNNBaseline(nn.Module):\n",
    "    def __init__(self, D, kernel_sizes, num_filters = 3):\n",
    "        super(CNNBaseline, self).__init__()\n",
    "        self.convs = nn.ModuleList([nn.Conv1d(in_channels=D, out_channels=num_filters, kernel_size=K) for K in kernel_sizes])\n",
    "        self.linear = nn.Linear(len(kernel_sizes) * num_filters, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = [torch.nn.functional.relu(conv(x)) for conv in self.convs]\n",
    "        x = [torch.nn.functional.max_pool1d(conv, conv.shape[2]) for conv in x] \n",
    "        x = torch.cat(x, dim=1).squeeze(2)\n",
    "\n",
    "        out = self.linear(x)\n",
    "        return out.squeeze()\n",
    "\n",
    "\n",
    "kernel_sizes = [2] * 10 + [3] * 10 + [4] * 10 + [5] * 10\n",
    "model = CNNBaseline(768, kernel_sizes)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WxN7kWGCoDdt"
   },
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HEho9hwrmudq"
   },
   "outputs": [],
   "source": [
    "def batch_generator(X, y, batch_size):\n",
    "    np.random.seed(42)\n",
    "    perm = np.random.permutation(len(X))\n",
    "    for start_index in range(0, len(perm), batch_size):\n",
    "        batch_indexes = perm[start_index:start_index + batch_size]\n",
    "        X_batch = X[batch_indexes]\n",
    "        y_batch = y[batch_indexes]\n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vFySogOXKMuw"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, X, y):\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for X_batch, y_batch in batch_generator(X, y, 256):\n",
    "\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        pred = model(X_batch)\n",
    "        _, preds = torch.max(pred, dim=1)\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(pred, y_batch)\n",
    "        losses.append(loss.item())  \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        correct_predictions += torch.sum(preds == y_batch)\n",
    "      \n",
    "    return correct_predictions.double() / y.shape[0], np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q6dNPjA7KNT1"
   },
   "outputs": [],
   "source": [
    "def eval_model(model, X, y):\n",
    "    model = model.eval()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in batch_generator(X, y, 256):\n",
    "\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            pred = model(X_batch)\n",
    "            _, preds = torch.max(pred, dim=1)\n",
    "            loss = loss_fn(pred, y_batch)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            correct_predictions += torch.sum(preds == y_batch)\n",
    "        \n",
    "    return correct_predictions.double() / y.shape[0], np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n4t8adEJKd6P"
   },
   "outputs": [],
   "source": [
    "def train_model(mode, model, X_train, y_train, X_val, y_val, n_epoch):\n",
    "    if mode == 'train':\n",
    "        %%time\n",
    "        history_train_loss = []\n",
    "        history_val_loss = []\n",
    "        history_train_acc = []\n",
    "        history_val_acc = []\n",
    "        best_accuracy = 0\n",
    "\n",
    "        for epoch in range(n_epoch):\n",
    "\n",
    "            train_acc, train_loss = train_epoch(model, X_train, y_train)\n",
    "            val_acc, val_loss = eval_model(model, X_val, y_val)\n",
    "\n",
    "            history_train_acc.append(train_acc)\n",
    "            history_train_loss.append(train_loss)\n",
    "            history_val_acc.append(val_acc)\n",
    "            history_val_loss.append(val_loss)\n",
    "\n",
    "            if val_acc > best_accuracy:\n",
    "                torch.save(model.state_dict(), 'best_model_state.bin')\n",
    "                best_accuracy = val_acc\n",
    "\n",
    "        print()\n",
    "        print(f'train loss {train_loss} accuracy {train_acc}')\n",
    "        print(f'val   loss {val_loss} accuracy {val_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m3RFhgfxRdkB"
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "CNN = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "EI8F6u4Jj1O9",
    "outputId": "4a087234-c9f5-44f6-cc83-fc779ec3c2dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 5.96 µs\n",
      "\n",
      "train loss 0.024864014105073044 accuracy 0.998125\n",
      "val   loss 0.41555437445640564 accuracy 0.845\n"
     ]
    }
   ],
   "source": [
    "train_model('train', CNN, X_train, y_train, X_val, y_val, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xuDrO0gbAIZz"
   },
   "outputs": [],
   "source": [
    "pred = CNN(X_test.to(device))\n",
    "_, preds = torch.max(pred, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "biRJAPMwAInA"
   },
   "outputs": [],
   "source": [
    "ans = pd.DataFrame({'Id' : np.arange(0, len(preds.cpu())), 'y' : np.array(preds.cpu())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MXzURC8OAJNg"
   },
   "outputs": [],
   "source": [
    "ans.to_csv('/content/gdrive/My Drive/sentiment_analysis_on_movie_reviews/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZYGrg_GQNZaq"
   },
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aV62z8xLZvB7"
   },
   "outputs": [],
   "source": [
    "def report_baseline(X_train, y_train, X_test, y_test, model):\n",
    "\n",
    "    if model == 'LogisticRegression':\n",
    "        clf = LogisticRegression(random_state = 42)\n",
    "        clf.fit(X_train[:, 0, :], y_train)\n",
    "\n",
    "    elif model == 'RandomForestClassifier':\n",
    "        clf = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42)\n",
    "        clf.fit(X_train[:, 0, :], y_train)\n",
    "\n",
    "    else:\n",
    "        clf = SVC(kernel = 'rbf', gamma = 1e-3, C = 100)\n",
    "        clf.fit(X_train[:, 0, :], y_train)\n",
    "\n",
    "    return classification_report(clf.predict(X_test[:, 0, :]), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y_v77kV3t2FL"
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "colab_type": "code",
    "id": "Gcdfbb54ZL6k",
    "outputId": "c28e9f09-f209-4b73-e959-1999846f03f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76       141\n",
      "           1       0.86      0.88      0.87       259\n",
      "\n",
      "    accuracy                           0.83       400\n",
      "   macro avg       0.82      0.81      0.82       400\n",
      "weighted avg       0.83      0.83      0.83       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report_baseline(X_train, y_train, X_val, y_val, 'LogisticRegression'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KFdb8PpQt7Ag"
   },
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "colab_type": "code",
    "id": "ciE6F4JDZlLP",
    "outputId": "877b5a88-89b7-44e6-ece8-351afc43f49d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.66      0.68       140\n",
      "           1       0.82      0.84      0.83       260\n",
      "\n",
      "    accuracy                           0.78       400\n",
      "   macro avg       0.76      0.75      0.75       400\n",
      "weighted avg       0.78      0.78      0.78       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report_baseline(X_train, y_train, X_val, y_val, 'RandomForestClassifier'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m46JGboNuBT4"
   },
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "colab_type": "code",
    "id": "XgB9C6IpbilC",
    "outputId": "31cc86f2-82f5-4a1e-97d5-3f528ec57bf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76       135\n",
      "           1       0.88      0.88      0.88       265\n",
      "\n",
      "    accuracy                           0.84       400\n",
      "   macro avg       0.82      0.82      0.82       400\n",
      "weighted avg       0.84      0.84      0.84       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report_baseline(X_train, y_train, X_val, y_val, 'SVM'))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "3. sentiment_analysis_simple.ipynb\"",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
