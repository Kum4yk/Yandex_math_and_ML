{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Зачем нужно масштабировать признаки перед обучением линейной модели?\n",
    "\n",
    "\n",
    "- Линейная модель не будет иметь смысла при обучении на признаках с разным масштабом.\n",
    "\n",
    "\n",
    "- **Градиентный спуск может очень медленно сходиться при разном масштабе признаков.**\n",
    "\n",
    "\n",
    "- Благодаря масштабированию выборка будет занимать меньше места в оперативной памяти, что позволит ускорить процесс обучения.  \n",
    "(Мы имеем дело с numpy где место под данные резевируется как в строгой типизации)\n",
    "___\n",
    " \n",
    "\n",
    "#### 2. Пусть в выборке 4 признака, и мы решили попробовать добавить квадратичные признаки — то есть все квадраты и попарные произведения исходных признаков. Сколько признаков мы получим после такого расширения?\n",
    "\n",
    "$$ 4  + 4  + \\binom{4}{2} = [или] = 4 + \\overline{\\binom{4}{2}} = 14$$\n",
    "\n",
    "___\n",
    " \n",
    "#### 3. Выберите верные утверждения про бинарное кодирование категориальных признаков.\n",
    "\n",
    "\n",
    "- **Для кодирования требуется столько бинарных признаков, сколько значений мог принимать исходный категориальный признак.**\n",
    "\n",
    "\n",
    "- Бинарное кодирование категориальных признаков является способом регуляризации линейных моделей. -\n",
    "\n",
    "\n",
    "- **Если обучить над бинарным кодированием линейную модель, то получится, что каждому значению исходного категориального признака будет соответствовать свой вес.**\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
