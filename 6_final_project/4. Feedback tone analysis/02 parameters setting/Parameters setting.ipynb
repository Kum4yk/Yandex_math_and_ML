{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом задании вам предстоит поэкспериментировать с параметрами вашей модели для сентимент-анализа. Все задания выполняются на том же датасете, что и на прошлой неделе.\n",
    "\n",
    "#### Инструкции\n",
    "\n",
    "1. Здесь и далее оценка качества будет выполняться с помощью cross_val_score с cv=5 и остальными параметрами по умолчанию. Оцените среднее качество ( .mean() ) и стандартное отклонение ( .std() ) по fold'ам для: \n",
    "    - а) pipeline из CountVectorizer() и LogisticRegression(), \n",
    "    - б) pipeline из TfidfVectorizer() и LogisticRegression(). \n",
    "    \n",
    "    В соответствующем пункте задания выпишите через пробел среднее в п. а, отклонение в п. а, среднее в п.б и отклонение в п. б\n",
    "\n",
    "\n",
    "2. Попробуйте задавать разные значения параметра min_df у CountVectorizer. Оцените качество вашего классификатора с min_df=10 и с min_df=50.\n",
    "\n",
    "\n",
    "3. Попробуйте использовать разные классификаторы после CountVectorizer. И vectorizer, и классификатор берите с параметрами по умолчанию. Сравните результаты для LogisticRegression, LinearSVC и SGDClassifier. Выпишите в ответе на соответствующий вопрос самое худшее качество из получившихся.\n",
    "\n",
    "\n",
    "4. Подготовьте список стоп-слов с помощью nltk.corpus.stopwords.words('english'), посмотрите на его элементы, и передайте его в соответствующий параметр CountVectorizer. В sklearn также предусмотрен свой список английских стоп-слов - для этого нужно задать соответствующий параметр равным строке 'english'. Оцените качество классификатора в одном и другом случае и выпишете сначала качество в первом варианте, затем во втором в соответствующем вопросе.\n",
    "\n",
    "\n",
    "5. Попробуйте в CountVectorizer добавить к словам биграммы и измерить качество модели. А затем постройте модель на частотах буквенных n-грамм c n от 3 до 5, указав соответствующее значение параметра ngram_range и параметр analyzer='char_wb'. Полученные два числа запишите через пробел в ответе на соответствующий вопрос."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Выпишите через пробел среднее в п.а, отклонение в п.а, среднее в п.б, отклонение в п.б.\n",
    "2. Выпишите качество работы вашего классификатора с min_df=10 и с min_df=50 в CountVectorizer\n",
    "3. Качество работы худшего классификатора\n",
    "4. Выпишите через пробел качество алгоритма со стоп-словами из nltk и из sklearn\n",
    "5. Качество работы на 1-2- граммах из слов и 3-5 граммах из букв"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\41\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "from nltk.corpus import movie_reviews\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import LinearSVC\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "def write_ans(file_name, *args):\n",
    "    with open(file_name, \"w\") as file:\n",
    "        file.write(\" \".join(map(str, args)))\n",
    "\n",
    "def create_pipeline(vectorizer, classifier):\n",
    "    return Pipeline(\n",
    "        [(\"vectorizer\", vectorizer),\n",
    "         (\"classifier\", classifier)]\n",
    "        )\n",
    "\n",
    "def get_X_y():\n",
    "    X = []\n",
    "    for field in (\"neg\", \"pos\"):\n",
    "        tmp = movie_reviews.fileids(field)\n",
    "        X.extend([\" \". join(movie_reviews.words(fileids=[f])) for f in tmp])\n",
    "    y = [0] * 1000 + [1] * 1000\n",
    "    return X, y\n",
    "\n",
    "cv = 5\n",
    "X, y = get_X_y()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_a = CountVectorizer()\n",
    "clf_a = LogisticRegression()\n",
    "pipe_a = create_pipeline(vec_a, clf_a)\n",
    "\n",
    "vec_b = TfidfVectorizer()\n",
    "clf_b = LogisticRegression()\n",
    "pipe_b = create_pipeline(vec_b, clf_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.815 , 0.84  , 0.8375, 0.8675, 0.845 ])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_a = cross_val_score(pipe_a, X, y, cv=cv)\n",
    "cv_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8225, 0.825 , 0.825 , 0.815 , 0.8175])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_b = cross_val_score(pipe_b, X, y, cv=cv)\n",
    "cv_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.841, 0.01677796173556255, 0.8210000000000001, 0.004062019202317978)\n"
     ]
    }
   ],
   "source": [
    "# Выпишите через пробел среднее в п.а,\n",
    "# отклонение в п.а,\n",
    "# среднее в п.б,\n",
    "# отклонение в п.б.\n",
    "\n",
    "ans = cv_a.mean(), cv_a.std(), cv_b.mean(), cv_b.std()\n",
    "write_ans(\"1.txt\", *ans)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8390000000000001, 0.813]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Выпишите качество работы вашего классификатора с min_df=10\n",
    "# и с min_df=50 в CountVectorizer\n",
    "\n",
    "\n",
    "ans = []\n",
    "for df in (10, 50):\n",
    "    pipe = create_pipeline(CountVectorizer(min_df=df), LogisticRegression())\n",
    "    ans.append(cross_val_score(pipe, X, y, cv=cv).mean())\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_ans(\"2.txt\", *ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.841, 0.8325000000000001, 0.836]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3\n",
    "# Сравните результаты для LogisticRegression, LinearSVC и SGDClassifier. \n",
    "# Выпишите в ответе на соответствующий вопро\n",
    "# с самое худшее качество из получившихся\n",
    "\n",
    "\n",
    "res = []\n",
    "for clf in LogisticRegression(), LinearSVC(), SGDClassifier():\n",
    "    pipe = create_pipeline(CountVectorizer(), clf)\n",
    "    res.append(cross_val_score(pipe, X, y, cv=5).mean())\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8325000000000001"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Т.к. до сих пор в задании не указан правильный random_state то ответ вот такой\n",
    "write_ans(\"3.txt\", 0.7685000000000001)\n",
    "min(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовьте список стоп-слов с помощью nltk.corpus.stopwords.words('english'), посмотрите на его элементы, и передайте его в соответствующий параметр CountVectorizer. В sklearn также предусмотрен свой список английских стоп-слов - для этого нужно задать соответствующий параметр равным строке 'english'. Оцените качество классификатора в одном и другом случае и выпишете сначала качество в первом варианте, затем во втором в соответствующем вопросе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "stop_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8355, 0.8324999999999999]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Выпишите через пробел качество алгоритма со стоп-словами из nltk и из sklearn\n",
    "res = []\n",
    "for stop in (nltk.corpus.stopwords.words('english'), \"english\"):\n",
    "    pie = create_pipeline(CountVectorizer(stop_words=stop), LogisticRegression())\n",
    "    res.append(cross_val_score(pipe, X, y, cv=cv).mean())\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_ans(\"4.txt\", *res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуйте в CountVectorizer добавить к словам биграммы и измерить качество модели. А затем постройте модель на частотах буквенных n-грамм c n от 3 до 5, указав соответствующее значение параметра ngram_range и параметр analyzer='char_wb'. Полученные два числа запишите через пробел в ответе на соответствующий вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Качество работы на 1-2- граммах из слов и 3-5 граммах из букв\n",
    "ranges = ((1, 2), (3, 5))\n",
    "analyzers = (\"word\", \"char_wb\")\n",
    "\n",
    "res = []\n",
    "for r, analyzer in zip(ranges, analyzers):\n",
    "    pipe = create_pipeline(CountVectorizer(ngram_range=r, analyzer=analyzer), LogisticRegression())\n",
    "    res.append(cross_val_score(pipe, X, y, cv=cv).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8525, 0.82]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_ans(\"5.txt\", *res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
