{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Вопрос 1. Какие из перечисленных подходов к задаче поиска минимума не требуют существования градиента у оптимизируемой функции?\n",
    "- Метод градиентного спуска.\n",
    "- Дифференциальная эволюция. (+)\n",
    "- Метод имитации отжига. (+)\n",
    "- Аналитическое нахождение точки минимума с помощью необходимого условия экстремума.\n",
    "\n",
    "##### Вопрос 2. Как вы думаете, зачем нужна стадия мутации в генетических алгоритмах?\n",
    "- Чтобы с большей точностью двигаться на каждом шаге по градиенту сглаженной функции.\n",
    "- Чтобы лучше попадать в локальные минимумы.\n",
    "- Чтобы популяция не вырождалась слишком быстро в набор очень похожих друг на друга векторов и был некоторый шанс выбивания из локальных минимумов. (+)\n",
    "\n",
    "##### Вопрос 3. Почему при поиске минимума методом имитации отжига допускаются переходы в точки, в которых функция принимает большие значения, нежели в текущей?\n",
    "- Чтобы метод быстрее сходился.\n",
    "- Чтобы метод мог иногда выбираться из локальных минимумов. (+)\n",
    "- Чтобы более точно моделировать физический процесс отжига.\n",
    "\n",
    "##### Вопрос 4. В каких случаях стоит применять методы оптимизации, не использующие градиент?\n",
    "- Во всех случаях, т.к. очень часто неградиентные методы сходятся быстрее градиентных.\n",
    "- В случаях, когда у функции нет градиента. А также в случаях, когда нужно найти глобальный экстремум функции, а градиентные методы скорее всего будут попадать в локальный. (+)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
