![Ya-Icon-new-size.jpg](attachment:Ya-Icon-new-size.jpg)

### Описание:
Не так давно получил распространение термин «большие данные», обозначивший новую прикладную область — поиск способов автоматического быстрого анализа огромных объёмов разнородной информации. Наука о больших данных ещё только оформляется, но уже сейчас она очень востребована — и в будущем будет востребована только больше.
С её помощью можно решать невероятные задачи: оценивать состояние печени по кардиограмме, предсказывать зарплату по описанию вакансии, предлагать пользователю музыку на основании его анкеты в интернете.

Большими данными может оказаться что угодно: результаты научных экспериментов, логи банковских транзакций, метеорологические наблюдения, профили в социальных сетях — словом, всё, что может быть полезно проанализировать.
Самым перспективным подходом к анализу больших данных считается применение машинного обучения — набора методов, благодаря которым компьютер может находить в массивах изначально неизвестные взаимосвязи и закономерности.

На факультете компьютерных наук ВШЭ и в Школе анализа данных есть люди, активно использующие машинное обучение и разрабатывающие новые подходы к нему. Именно они — преподаватели этого курса.

Вы изучите основные типы задач, решаемых с помощью машинного обучения — в основном речь пойдёт о классификации, регрессии и кластеризации. Узнаете об основных методах машинного обучения и их особенностях, научитесь оценивать качество моделей — и решать, подходит ли модель для решения конкретной задачи. Наконец, познакомитесь с современными библиотеками, в которых реализованы обсуждаемые модели и методы оценки их качества. Для работы мы будем использовать реальные данные из реальных задач.

### Содержание по неделям:
1. **Знакомство с анализом данных и машинным обучением.** Добро пожаловать! В первом модуле курса мы расскажем о задачах, которые решает машинное обучение, определим базовый набор понятий и введем необходимые обозначения. Также мы расскажем про основные библиотеки языка Python для работы с данными (NumPy, Pandas, Scikit-Learn), которые понадобятся для выполнения практических заданий на протяжении всего курса.
    **Логические методы классификации.** Логические методы делают классификацию объектов на основе простых правил, благодаря чему являются интерпретируемыми и легкими в реализации. При объединении в композицию логические модели позволяют решать многие задачи с высоким качеством. В этом модуле мы изучим основной класс логических алгоритмов — решающие деревья. Также мы поговорим про объединение деревьев в композицию, называемую случайным лесом.
2. **Метрические методы классификации.** Метрические методы проводят классификацию на основе сходства, благодаря чему могут работать на данных со сложной структурой — главное, чтобы между объектами можно было измерить расстояние. Мы изучим метод k ближайших соседей, а также способ его обобщения на задачи регрессии с помощью ядерного сглаживания.
    **Линейные методы классификации.** Линейные модели — один из наиболее изученных классов алгоритмов в машинном обучении. Они легко масштабируются и широко применяются для работы с большими данными. В этом модуле мы изучим метод стохастического градиента для настойки линейных классификаторов, познакомимся с регуляризацией и обсудим некоторые тонкости работы с линейными методами.
3. **Метод опорных векторов и логистическая регрессия.** Линейные методы имеют несколько очень важных подвидов, о которых пойдет речь в этом модуле. Метод опорных векторов максимизирует отступы объектов, что тесно связано с минимизацией вероятности переобучения. При этом он позволяет очень легко перейти к построению нелинейной разделяющей поверхности благодаря ядровому переходу. Логистическая регрессия позволяет оценивать вероятности принадлежености классам, что оказывается полезным во многих прикладных задачах.
    **Метрики качества классификации.** В машинном обучении существует большое количество метрик качества, каждая из которых имеет свою прикладную интерпретацию и направлена на измерение конкретного свойства решения. В этом модуле мы обсудим, какие бывают метрики качества бинарной и многоклассовой классификации, а также рассмотрим способы сведения многоклассовых задач к двухклассовым.
4. **Линейная регрессия**. В этом модуле мы изучим линейные модели для регрессии и обсудим их связь с сингулярным разложением матрицы "объекты-признаки".
    **Понижение размерности и метод главных компонент**. В прикладных задачах часто возникает потребность в уменьшении количества признаков — например, для ускорения работы моделей. В этом модуле мы обсудим подходы к отбору признаков, а также изучим метод главных компонент, один из самых популярных методов понижения размерности.
5. **Композиции алгоритмов**. Объединение большого числа моделей в композицию может значительно улучшить итоговое качество за счет того, что отдельные модели будут исправлять ошибки друг друга. В этом модуле мы обсудим основные понятия и постановки задач, связанные с композициями, и обсудим один из наиболее распространенных способов их построения — градиентный бустинг.
    **Нейронные сети**. Нейронные сети позволяют находить сложные нелинейные разделяющие поверхности, благодаря чему широко используются в таких трудных задачах, как распознавание изображений и речи. В этом модуле мы изучим многослойные нейронные сети и их настройку с помощью метода обратного распространения ошибки. Также мы поговорим о глубоких нейросетях, их архитектурах и особенностях.
6. **Кластеризация и визуализация**. Этот модуль посвящен новому классу задач в машинном обучении — обучению без учителя. Под этим понимаются ситуации, в которых нужно найти структуру в данных или произвести их "разведку". В этом модуле мы обсудим две таких задачи: кластеризацию (поиск групп схожих объектов) и визуализацию (отображение объектов в двух- или трехмерное пространство).
    **Частичное обучение**. Под частичным обучение понимается задача, находящаяся между обучением с учителем и кластеризацией: дана выборка, в которой значение целевой переменной известно лишь для части объектов. Такие ситуации встречаются, когда разметка объектов является дорогой операцией, но при этом достаточно дешево можно подсчитать признаки для объектов. В этом модуле мы обсудим отличия частичного обучения от рассмотренных ранее постановок, и разберем несколько подходов к решению.
7. **Машинное обучение в прикладных задачах**. В этом модуле мы подведем итоги курса, вспомним основные этапы решения задачи анализа данных. Также мы разберем несколько задач из прикладных областей, чтобы подготовиться к выполнению финального проекта.


### [Link](https://www.coursera.org/learn/vvedenie-mashinnoe-obuchenie/)
