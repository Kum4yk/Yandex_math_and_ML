{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Выберите верные высказывания о нейросетевых методах.**\n",
    "\n",
    "\n",
    " - Метки классов при двухклассовой классификации могут принимать значения из множеств как $\\{0, 1\\}$, так и $\\{-1,1\\}$. $\\large \\checkmark$ (В первом случае можно использовать логистическую функцию активации, а во втором просто сигнум.)\n",
    "\n",
    "\n",
    " - Нейронная сеть, корректно аппроксимирующая обучающую выборку и плохо аппроксимирующая контрольную, недообучена. - \n",
    "\n",
    "\n",
    " - С помощью многослойной нейронной сети можно получить аппроксимацию высокой точности. $\\large \\checkmark$ (Да, потому что многослойные сети — сложная модель с многими степенями свободы)\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Выберите верные высказывания о функциях активации.**\n",
    "\n",
    "\n",
    " - Сигмоидная логистическая функция активации определяет вероятность принадлежности объекта к классу. $\\large \\checkmark$  (По определению)\n",
    "\n",
    "\n",
    " - Для решения задачи регрессии можно использовать тождественную (линейную) функцию активации. $\\large \\checkmark$  (Тогда получается обычная линейная регрессия.)\n",
    "\n",
    "\n",
    " - Функция “0-1 loss” предпочтительна при решении задачи регрессии. - \n",
    "\n",
    "\n",
    " - Функция активации обязательно должна быть дифференцируемой. - \n",
    "\n",
    "\n",
    " - **До получения выборки** мы можем указать оптимальный тип функции активации нейронов сети. (- )\n",
    "\n",
    "\n",
    " - Функция-галочка является дифференцируемой. - \n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Выберите верные высказывания о методах настройки параметров нейросетей.**\n",
    "\n",
    "\n",
    " - Алгоритмы градиентного спуска всегда предпочтительнее стохастических. - \n",
    "\n",
    "\n",
    " - Алгоритм градиентного спуска в любой задаче найдет глобальный минимум. - \n",
    "\n",
    "\n",
    " - Алгоритмы градиентного спуска требуют дифференцируемых функций ошибки. $\\large \\checkmark$  \n",
    "\n",
    "\n",
    " - Алгоритм стохастического градиента обязательно использует все элементы выборки. -\n",
    "\n",
    "\n",
    " - Функция ошибки имеет единственный минимум. - \n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Параметр нейронной сети можно удалить, если:**\n",
    "\n",
    "\n",
    " - его значение велико.\n",
    "\n",
    "\n",
    " - его удаление не изменяет значение функции ошибки существенно. $\\large \\checkmark$ \n",
    "\n",
    "\n",
    " - его значение равно нулю. $\\large \\checkmark$ \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Выберите верные высказывания о регуляризации нейросетей.**\n",
    "\n",
    "\n",
    " - Регуляризация загрубляет настройку параметров. $\\large \\checkmark$ \n",
    "\n",
    "\n",
    " - Регуляризация снижает число параметров нейронной сети.\n",
    "\n",
    "\n",
    " - Увеличение коэффициента регуляризации повышает точность аппроксимации. -\n",
    "\n",
    "\n",
    " - Увеличение коэффициента регуляризации снижает переобученность сети. $\\large \\checkmark$ \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Выберите верные высказывания о качестве работы нейросетей.**\n",
    "\n",
    "\n",
    " - Двухслойная нейросеть может корректно разделить любую линейно разделимую выборку. $\\large \\checkmark$ \n",
    "\n",
    "\n",
    " - Любую непрерывную функцию нескольких аргументов можно представить как суперпозицию функций одного аргумента и функции суммирования. $\\large \\checkmark$ (Это утверждение называется теоремой Колмогорова.)\n",
    "\n",
    "\n",
    " - Существует такая нейронная сеть, которая аппроксимирует любую непрерывную разделяющую поверхность. $\\large \\checkmark$   (Универсальная теорема аппроксимации)\n",
    "\n",
    "\n",
    " - Существует нейронная сеть, у которой качество классификации лучше, чем у всех других алгоритмов классификации на любой выборке.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
